{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444b6ed2-71be-4944-b301-e3f0450acc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c94c11e-b323-4712-b3ba-73e66578a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = os.path.join('tr', \"*.txt\")\n",
    "spam_files = glob.glob(pattern)\n",
    "spam_counts = {}\n",
    "\n",
    "pattern = os.path.join('ham', \"*.txt\")\n",
    "ham_files = glob.glob(pattern)\n",
    "ham_counts = {}\n",
    "\n",
    "def get_counts(counts, files, sample_size=256):\n",
    "    #ix = torch.randint(0, len(files), (sample_size,)).tolist()\n",
    "    ix = range(0, sample_size)\n",
    "    for x in ix:\n",
    "        fp = files[x]\n",
    "        f = open(fp, 'r')\n",
    "        lines = f.read().split('\\n')[5:]\n",
    "        for line in lines:\n",
    "            words = line.split(' ')\n",
    "            words = [w.replace('\\t', '').replace('!', '').replace('.', '').replace(',', '').replace('?', '').replace('*', '').lower() for w in words]\n",
    "            for w in words:\n",
    "                if counts.get(w): counts[w] += 1\n",
    "                else: counts[w] = 1\n",
    "                    \n",
    "get_counts(spam_counts, spam_files, sample_size=len(spam_files))\n",
    "get_counts(ham_counts, ham_files, sample_size=len(ham_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9661af2b-2b23-45f4-abf3-94df57525a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309383\n",
      "[('and', 5543), ('to', 5311), ('the', 5095), ('of', 3977), ('you', 2677), ('for', 2623), ('a', 2583), ('on', 2399), ('in', 2248), ('your', 1962)]\n"
     ]
    }
   ],
   "source": [
    "ss = sum(spam_counts.values())\n",
    "print(ss)\n",
    "\n",
    "# WHITELIST\n",
    "spam_counts[' '] = 1\n",
    "spam_counts['͏'] = 1\n",
    "spam_counts[''] = 1\n",
    "spam_counts['\\u2007͏'] = 1\n",
    "spam_counts['\\u200c'] = 1\n",
    "spam_counts['\\xad'] = 1\n",
    "\n",
    "remove = []\n",
    "for (k,v) in spam_counts.items():\n",
    "    if v/ss > 0.02 or v/ss <= 3/ss: remove.append(k)\n",
    "for r in remove: spam_counts.pop(r)\n",
    "\n",
    "sorted_spam_counts = sorted(spam_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_spam_counts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7bc66bf-26c5-4c02-8db6-02bf507fd77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638093\n",
      "[('', 58252), ('͏', 43974), ('and', 9919), ('the', 8977), ('\\u200c', 7819), ('to', 7090), ('for', 5733), ('a', 5388), ('of', 5151), ('off', 5135)]\n"
     ]
    }
   ],
   "source": [
    "sh = sum(ham_counts.values())\n",
    "print(sh)\n",
    "\n",
    "sorted_ham_counts = sorted(ham_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_ham_counts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5ad9d6-d1f6-4011-93f3-d6d6e147b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine likelihood that the message is spam given that 'w' appears in it\n",
    "def spam_prob(w):\n",
    "    ss = sum(spam_counts.values())\n",
    "    sh = sum(ham_counts.values())\n",
    "    ps = 0\n",
    "    if spam_counts.get(w): ps = spam_counts[w]\n",
    "    ph = 0\n",
    "    if ham_counts.get(w): ph = ham_counts[w]\n",
    "    if ph == 0 and ps == 0: return 0.5\n",
    "    p = (ps / ss) / ((ps / ss) + (ph / sh))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e5ae02-4464-4f17-85c1-28ea8751b053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "university\n",
      "best\n",
      "admissions\n",
      "campus\n",
      "sponsored\n",
      "1919\n"
     ]
    }
   ],
   "source": [
    "# words in the spam corpus that are likely spam\n",
    "spam_words = []\n",
    "for item in sorted_spam_counts:\n",
    "    if spam_prob(item[0]) > 0.90:\n",
    "        spam_words.append(item[0])\n",
    "\n",
    "for w in spam_words[:5]: print(w)\n",
    "print(len(spam_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb4618d5-b4f2-44cc-bb19-dc860ac91828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      "to\n",
      "the\n",
      "of\n",
      "you\n",
      "2636\n"
     ]
    }
   ],
   "source": [
    "# words in the spam corpus that are likely not spam\n",
    "not_spam = []\n",
    "for item in sorted_spam_counts:\n",
    "    if spam_prob(item[0]) <= 0.90:\n",
    "        not_spam.append(item[0])\n",
    "        \n",
    "for w in not_spam[:5]: print(w)\n",
    "print(len(not_spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72032030-eb43-47fe-ae1d-9b81a1197ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39958163839324046\n"
     ]
    }
   ],
   "source": [
    "spam_probs = []\n",
    "for fp in ham_files:\n",
    "    f = open(fp, 'r')\n",
    "    lines = f.read().split('\\n')[5:]\n",
    "    for line in lines:\n",
    "        words = line.split(' ')\n",
    "        words = [w.replace('\\t', '').replace('!', '').replace('.', '').replace(',', '').replace('?', '').replace('*', '').lower() for w in words]\n",
    "        for w in words:\n",
    "            spam_probs.append(spam_prob(w))\n",
    "    spam_likelihood = sum(spam_probs) / len(spam_probs)\n",
    "    # most ham messages don't exceed 0.4\n",
    "    if spam_likelihood > 0.39:\n",
    "        print(spam_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72c448ac-9a7a-4b75-bed1-3229d485f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_probs = []\n",
    "for fp in spam_files:\n",
    "    f = open(fp, 'r')\n",
    "    lines = f.read().split('\\n')[5:]\n",
    "    for line in lines:\n",
    "        words = line.split(' ')\n",
    "        words = [w.replace('\\t', '').replace('!', '').replace('.', '').replace(',', '').replace('?', '').replace('*', '').lower() for w in words]\n",
    "        for w in words:\n",
    "            spam_probs.append(spam_prob(w))\n",
    "    spam_likelihood = sum(spam_probs) / len(spam_probs)\n",
    "    # most spam messages don't go below 0.44\n",
    "    if spam_likelihood < 0.44:\n",
    "        print(spam_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68f3fc-a641-4091-b243-5ea1b8870675",
   "metadata": {},
   "source": [
    "### Further Optimizations\n",
    "We can just ignore all words that have a spamicity of around $0.5$, ie: words that appear around the same amount of times\n",
    "in both of our datasets. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
